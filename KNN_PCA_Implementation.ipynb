{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_vector():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    files = filedialog.askopenfilenames()\n",
    "    dataset = np.zeros(shape = (len(files), 360, 360))\n",
    "    \n",
    "    for i in range(0, len(files)):\n",
    "        dataset[i] = imread(files[i], flatten = 1)\n",
    "    dataset = dataset / 255\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    test_data_filename = filedialog.askopenfilename()\n",
    "    file = open(test_data_filename, \"r\")\n",
    "\n",
    "    test_data = []\n",
    "    for line in file:\n",
    "        processed_line = line.split(\",\")[1].strip(\" ;\\n\").split(\" \")\n",
    "        for i in range(len(processed_line)):\n",
    "            processed_line[i] = 1 if int(processed_line[i]) > 0.5 else 0\n",
    "\n",
    "        test_data.append(processed_line)\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_training_and_testing_sets(dataset, num_imgs, test_data):\n",
    "    # produce arrays made up of approx. 80% of the input and approx. 20% of the\n",
    "    # input, respectively\n",
    "    training_size = int(np.floor(num_imgs * .8))\n",
    "    X_train = np.array(dataset[0:training_size])\n",
    "    X_test = np.array(dataset[training_size:len(dataset)])\n",
    "\n",
    "    # produce arrays containing the data from the text file using length and\n",
    "    # dimensions of the input arrays\n",
    "    y_train = np.array(test_data[0:training_size])\n",
    "    y_test = np.array(test_data[training_size:len(dataset)])\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset = image_to_vector()\n",
    "    test = load_test_data()\n",
    "    return make_training_and_testing_sets(dataset,3600, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, x_test, k):\n",
    "    distances = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        # compute euclidean distance between the observation and all of the\n",
    "        # data points in the training set\n",
    "        distance = np.sqrt(np.sum(np.square(x_test - X_train[i, :])))\n",
    "\n",
    "        # add it to the list of distances\n",
    "        distances.append([distance, i])\n",
    "\n",
    "    # sort the list so that it will be easy to find each data point's nearest\n",
    "    # neighbors\n",
    "    distances = sorted(distances)\n",
    "\n",
    "    # make a list of the k neighbors' targets\n",
    "    for i in range(k):\n",
    "        index = distances[i][1]\n",
    "        targets.append(y_train[index])\n",
    "\n",
    "    # return the most common target\n",
    "    unique_targets, counts = np.unique(targets, return_counts=True)\n",
    "    counts_to_targets = dict(zip(counts, unique_targets))\n",
    "    return counts_to_targets[np.amax(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, y_train, X_test, predictions, k):\n",
    "    # train on the input data\n",
    "    \n",
    "    train(X_train, y_train)\n",
    "    # loop over all observations\n",
    "    for i in range(len(X_test)):\n",
    "        predictions.append(predict(X_train, y_train, X_test[i, :], k))\n",
    "\n",
    "\n",
    "knn(X_train, y_train, X_test, predictions, k)\n",
    "predictions = np.asarray(predictions)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"\\nThe accuracy of our classifier is {0}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
